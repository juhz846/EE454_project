{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "397b968f",
      "metadata": {
        "id": "397b968f",
        "outputId": "9353e975-1997-4080-c2b5-60287f23a2f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello world\n",
            "hello vish\n"
          ]
        }
      ],
      "source": [
        "print(\"hello world\")\n",
        "\n",
        "print(\"hello vish\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CUDA Setup"
      ],
      "metadata": {
        "id": "e1362963"
      },
      "id": "e1362963"
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking cuda version\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyEQ8BScMLDJ",
        "outputId": "237d09d4-8450-4912-ec2b-6c5c8a842f1d"
      },
      "id": "xyEQ8BScMLDJ",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter # run cuda from jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LDkoBdEMNjg",
        "outputId": "acc3f49c-62de-42df-fcc2-e9b24c31937c"
      },
      "id": "1LDkoBdEMNjg",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvcc4jupyter\n",
            "  Downloading nvcc4jupyter-1.2.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Downloading nvcc4jupyter-1.2.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n",
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp5qrwbxjy\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download MNIST"
      ],
      "metadata": {
        "id": "6ywPGjbZ064z"
      },
      "id": "6ywPGjbZ064z"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "!wget -q http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "!gunzip *.gz\n",
        "!pwd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5tQEVOm1B6M",
        "outputId": "aae7792c-00bf-428f-addf-44b0b027a00c"
      },
      "id": "U5tQEVOm1B6M",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: *.gz: No such file or directory\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demo CUDA program"
      ],
      "metadata": {
        "id": "j48ciGEIMQaz"
      },
      "id": "j48ciGEIMQaz"
    },
    {
      "cell_type": "code",
      "source": [
        "  %%cuda\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void maxi(int* a, int* b, int n)\n",
        "{\n",
        "    int block = 256 * blockIdx.x;\n",
        "    int max = 0;\n",
        "\n",
        "    for (int i = block; i < min(256 + block, n); i++) {\n",
        "\n",
        "        if (max < a[i]) {\n",
        "            max = a[i];\n",
        "        }\n",
        "    }\n",
        "    b[blockIdx.x] = max;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "\n",
        "    int n;\n",
        "    n = 10;\n",
        "    int a[n];\n",
        "\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        a[i] = rand() % n;\n",
        "        cout << a[i] << \"\\t\";\n",
        "    }\n",
        "\n",
        "    cout << endl;\n",
        "\n",
        "    cudaEvent_t start, end;\n",
        "    int *ad, *bd;\n",
        "    int size = n * sizeof(int);\n",
        "    cudaMalloc(&ad, size);\n",
        "    cudaMemcpy(ad, a, size, cudaMemcpyHostToDevice);\n",
        "    int grids = ceil(n * 1.0f / 256.0f);\n",
        "    cudaMalloc(&bd, grids * sizeof(int));\n",
        "\n",
        "    dim3 grid(grids, 1);\n",
        "    dim3 block(1, 1);\n",
        "\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&end);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    while (n > 1) {\n",
        "        maxi<<<grids, block>>>(ad, bd, n);\n",
        "        n = ceil(n * 1.0f / 256.0f);\n",
        "        cudaMemcpy(ad, bd, n * sizeof(int), cudaMemcpyDeviceToDevice);\n",
        "    }\n",
        "\n",
        "    cudaEventRecord(end);\n",
        "    cudaEventSynchronize(end);\n",
        "\n",
        "    float time = 0;\n",
        "    cudaEventElapsedTime(&time, start, end);\n",
        "\n",
        "    int ans[2];\n",
        "    cudaMemcpy(ans, ad, 4, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"The maximum element is : \" << ans[0] << endl;\n",
        "\n",
        "    cout << \"The time required : \";\n",
        "    cout << time << endl;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WYW8OAeMY7a",
        "outputId": "e953d762-7a04-4b5f-b82e-23ff53dbb48c"
      },
      "id": "4WYW8OAeMY7a",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\t6\t7\t5\t3\t5\t6\t2\t9\t1\t\n",
            "The maximum element is : 9\n",
            "The time required : 117.453\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# This is a program that takes in a randomly initialized 30 x 30 array and outputs\n",
        "# a 10 x 10 array where each element is the average of every 3 x 3 non-overlapping\n",
        "# window in the 30 x 30 array\n",
        "\n",
        "%%cuda\n",
        "#include <cstdio>\n",
        "#include <iostream>\n",
        "\n",
        "using namespace std;\n",
        "\n",
        "__global__ void averageMatrixWindows(float** input, float** output) {\n",
        "\n",
        "}\n",
        "\n",
        "int main() {\n",
        "  int size = 30;\n",
        "  int window_size = 3;\n",
        "\n",
        "  float* inp_matr[size];\n",
        "  for (int i = 0; i < size; i++) {\n",
        "    inp_matr[i] = new float[size];\n",
        "    for (int j = 0; j < size; j++)\n",
        "      inp_matr[i][j] = rand() % size;\n",
        "  }\n",
        "\n",
        "  float* out_matr[size / window_size];\n",
        "  for (int i = 0; i < size / window_size; i++)\n",
        "    out_matr[i] = new float[size / window_size];\n",
        "\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogT4WN-rMaLN",
        "outputId": "44cb8792-26ce-4f8c-a4e7-8aa8f443437c"
      },
      "id": "ogT4WN-rMaLN",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "#include <cstdio>\n",
        "#include <cstdlib>\n",
        "#include <cmath>\n",
        "#include <curand.h>\n",
        "#include <curand_kernel.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/host_vector.h>\n",
        "#include <cassert>\n",
        "#include <cuda_runtime.h>\n",
        "#include <vector>\n",
        "#include <fstream>\n",
        "#include <cstdint>\n",
        "\n",
        "\n",
        "void readMNISTImages(const std::string &filename, float *images, int &training_size, int &rows, int &cols) {\n",
        "    std::ifstream file(filename, std::ios::binary);\n",
        "\n",
        "    // Read the header\n",
        "    int magic_number = 0, num_images = 0;\n",
        "    file.read(reinterpret_cast<char *>(&magic_number), 4);\n",
        "    file.read(reinterpret_cast<char *>(&num_images), 4);\n",
        "    file.read(reinterpret_cast<char *>(&rows), 4);\n",
        "    file.read(reinterpret_cast<char *>(&cols), 4);\n",
        "\n",
        "    // Convert from big-endian to little-endian\n",
        "    magic_number = __builtin_bswap32(magic_number);\n",
        "    num_images = __builtin_bswap32(num_images);\n",
        "    rows = __builtin_bswap32(rows);\n",
        "    cols = __builtin_bswap32(cols);\n",
        "\n",
        "    // Ensure training_size does not exceed num_images in the dataset\n",
        "    if (training_size > num_images) {\n",
        "        std::cerr << \"Requested training size exceeds number of available images.\\n\";\n",
        "        training_size = num_images;\n",
        "    }\n",
        "\n",
        "    // Compute size of one image\n",
        "    int image_size = rows * cols;\n",
        "\n",
        "    // Read the required number of images into the array\n",
        "    for (int i = 0; i < training_size; ++i) {\n",
        "        std::vector<uint8_t> buffer(image_size);\n",
        "        file.read(reinterpret_cast<char *>(buffer.data()), image_size);\n",
        "        for (int j = 0; j < image_size; ++j) {\n",
        "            images[i * image_size + j] = buffer[j] / 255.0f; // Normalize to [0, 1]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    file.close();\n",
        "}\n",
        "\n",
        "void readMNISTLabels(const std::string &filename, float *labels, int training_size, int num_classes) {\n",
        "    std::ifstream file(filename, std::ios::binary);\n",
        "    if (!file.is_open()) {\n",
        "        std::cerr << \"Cannot open file: \" << filename << \"\\n\";\n",
        "        return;\n",
        "    }\n",
        "\n",
        "    // Read the header\n",
        "    int32_t magic_number = 0, num_labels = 0;\n",
        "    file.read(reinterpret_cast<char *>(&magic_number), 4);\n",
        "    file.read(reinterpret_cast<char *>(&num_labels), 4);\n",
        "\n",
        "    // Convert from big-endian to little-endian\n",
        "    magic_number = __builtin_bswap32(magic_number);\n",
        "    num_labels = __builtin_bswap32(num_labels);\n",
        "\n",
        "    // Ensure training_size does not exceed num_labels in the dataset\n",
        "    if (training_size > num_labels) {\n",
        "        std::cerr << \"Requested training size exceeds number of available labels.\\n\";\n",
        "        training_size = num_labels;\n",
        "    }\n",
        "\n",
        "    for (int i = 0; i < training_size * num_classes; i++) {\n",
        "      labels[i] = 0.0f;\n",
        "    }\n",
        "\n",
        "    // Read the labels and convert to one-hot\n",
        "    for (int i = 0; i < training_size; ++i) {\n",
        "        unsigned char label = 0;\n",
        "        file.read(reinterpret_cast<char *>(&label), 1);\n",
        "        labels[i * num_classes + static_cast<int>(label)] = 1.0f; // Set the one-hot value\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// Error checking macro\n",
        "#define CUDA_CALL(x) do { if((x)!=cudaSuccess) { \\\n",
        "    fprintf(stderr,\"Error at %s:%d: %s\\n\",__FILE__,__LINE__,cudaGetErrorString(x)); \\\n",
        "    exit(EXIT_FAILURE);}} while(0)\n",
        "\n",
        "// Indexing helpers\n",
        "inline __device__ __host__ int idx4(int n, int h, int w, int c, int H, int W, int C) {\n",
        "    return (((n * H) + h) * W + w) * C + c;\n",
        "}\n",
        "\n",
        "inline __device__ __host__ int idx3(int n, int h, int w, int H, int W) {\n",
        "    return (n*H*W + h*W + w);\n",
        "}\n",
        "\n",
        "// ---------------------------------------------\n",
        "// GPU kernels (Forward) [Same as before]\n",
        "// ---------------------------------------------\n",
        "__global__ void convForwardKernel(const float* __restrict__ input,\n",
        "                                  const float* __restrict__ kernel,\n",
        "                                  float* __restrict__ output,\n",
        "                                  int N, int H, int W, int C_in,\n",
        "                                  int K, int C_out) {\n",
        "    int n = blockIdx.x;\n",
        "    int h = threadIdx.y;\n",
        "    int w = threadIdx.x;\n",
        "    for (int co = 0; co < C_out; co++) {\n",
        "        float val = 0.0f;\n",
        "        for (int ci = 0; ci < C_in; ci++) {\n",
        "            for (int kh = 0; kh < K; kh++) {\n",
        "                for (int kw = 0; kw < K; kw++) {\n",
        "                    float iv = input[idx4(n, h+kh, w+kw, ci, H, W, C_in)];\n",
        "                    float kv = kernel[((ci * K + kh)*K + kw)*C_out + co];\n",
        "                    val += iv * kv;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        output[idx4(n, h, w, co, H - K + 1, W - K + 1, C_out)] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void maxPoolForwardKernel(const float* __restrict__ input,\n",
        "                                     float* __restrict__ output,\n",
        "                                     int* __restrict__ max_idx, // store argmax indices\n",
        "                                     int N, int H_in, int W_in, int C,\n",
        "                                     int stride) {\n",
        "    int n = blockIdx.x;\n",
        "    int oh = threadIdx.y;\n",
        "    int ow = threadIdx.x;\n",
        "    int hstart = oh * stride;\n",
        "    int wstart = ow * stride;\n",
        "    for (int c = 0; c < C; c++) {\n",
        "        float max_val = -1e10;\n",
        "        int max_pos = 0;\n",
        "        for (int i = 0; i < stride; i++) {\n",
        "            for (int j = 0; j < stride; j++) {\n",
        "                int in_idx = idx4(n,hstart+i,wstart+j,c,H_in,W_in,C);\n",
        "                float val = input[in_idx];\n",
        "                if (val > max_val) {\n",
        "                    max_val = val;\n",
        "                    max_pos = in_idx;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        int out_idx = idx4(n, oh, ow, c, H_in/stride, W_in/stride, C);\n",
        "        output[out_idx] = max_val;\n",
        "        max_idx[out_idx] = max_pos; // store where we took max from\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void fcForwardKernel(const float* __restrict__ input,\n",
        "                                const float* __restrict__ w,\n",
        "                                const float* __restrict__ b,\n",
        "                                float* __restrict__ output,\n",
        "                                int N, int D_in, int D_out) {\n",
        "    int n = blockIdx.x;\n",
        "    for (int d = 0; d < D_out; d++) {\n",
        "        float val = b[d];\n",
        "        for (int i = 0; i < D_in; i++) {\n",
        "            val += input[n*D_in + i]*w[i*D_out + d];\n",
        "        }\n",
        "        output[n*D_out + d] = val;\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void softmaxKernel(float* data, int N, int D) {\n",
        "    int n = blockIdx.x;\n",
        "    float maxval = -1e10;\n",
        "    for (int d = 0; d < D; d++) {\n",
        "        float v = data[n*D + d];\n",
        "        if (v > maxval) maxval = v;\n",
        "    }\n",
        "    float sum = 0.0f;\n",
        "    for (int d = 0; d < D; d++) {\n",
        "        float expv = expf(data[n*D + d]-maxval);\n",
        "        data[n*D + d] = expv;\n",
        "        sum += expv;\n",
        "    }\n",
        "    for (int d = 0; d < D; d++) {\n",
        "        data[n*D + d] /= sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "// ---------------------------------------------\n",
        "// GPU kernels (Backward)\n",
        "// ---------------------------------------------\n",
        "\n",
        "// Conv Backward Kernel\n",
        "// dOut: (N, H_out, W_out, C_out)\n",
        "// input: (N, H_in, W_in, C_in)\n",
        "// kernel: (C_in, K, K, C_out)\n",
        "//\n",
        "// dIn: gradient w.r.t input\n",
        "// dW: gradient w.r.t weights\n",
        "__global__ void convBackwardKernel(const float* __restrict__ input,\n",
        "                                   const float* __restrict__ dOut,\n",
        "                                   float* __restrict__ dIn,\n",
        "                                   float* __restrict__ dW,\n",
        "                                   int N, int H, int W, int C_in,\n",
        "                                   int K, int C_out) {\n",
        "    // We can have multiple kernels: one for dIn and one for dW for simplicity.\n",
        "    // dIn computation:\n",
        "    // Each thread: one element of input gradient\n",
        "    // A direct approach is expensive; consider reversed conv or partial expansions.\n",
        "    // For simplicity, we do a naive approach:\n",
        "\n",
        "    int n = blockIdx.x;\n",
        "    // We'll do a parallel reduction per output pixel contributing to a given input pixel\n",
        "    // This is naive and may be slow for large scale.\n",
        "    for (int h_in=0; h_in<H; h_in++) {\n",
        "        for (int w_in=0; w_in<W; w_in++) {\n",
        "            for (int c_in=0; c_in<C_in; c_in++) {\n",
        "                float grad_val=0.0f;\n",
        "                // sum over all c_out, kh, kw\n",
        "                for(int c_out=0;c_out<C_out;c_out++){\n",
        "                    for(int kh=0;kh<K;kh++){\n",
        "                        for(int kw=0;kw<K;kw++){\n",
        "                            int h_out = h_in - kh;\n",
        "                            int w_out = w_in - kw;\n",
        "                            if (h_out>=0 && w_out>=0 && h_out< (H-K+1) && w_out< (W-K+1)){\n",
        "                                float dout_val = dOut[idx4(n,h_out,w_out,c_out,H-K+1,W-K+1,C_out)];\n",
        "                                float w_val = dW[((c_in*K+kh)*K+kw)*C_out + c_out];\n",
        "                                grad_val += dout_val * w_val;\n",
        "                            }\n",
        "                        }\n",
        "                    }\n",
        "                }\n",
        "                dIn[idx4(n,h_in,w_in,c_in,H,W,C_in)] = grad_val;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "__global__ void convBackwardWeightKernel(const float* __restrict__ input,\n",
        "                                         const float* __restrict__ dOut,\n",
        "                                         float* __restrict__ dW,\n",
        "                                         int N, int H, int W, int C_in,\n",
        "                                         int K, int C_out) {\n",
        "    // accumulate gradients for weights\n",
        "    // w_grad shape = (C_in,K,K,C_out)\n",
        "    // Let's do a simple approach: one thread per weight\n",
        "    int c_in = threadIdx.x;\n",
        "    int kh   = threadIdx.y;\n",
        "    int kw   = threadIdx.z;\n",
        "    int c_out = blockIdx.x;\n",
        "\n",
        "    float grad = 0.0f;\n",
        "    for (int n=0;n<N;n++){\n",
        "        for (int h_out=0;h_out<H-K+1;h_out++){\n",
        "            for (int w_out=0;w_out<W-K+1;w_out++){\n",
        "                float val_in = input[idx4(n, h_out+kh, w_out+kw, c_in, H, W, C_in)];\n",
        "                float val_dout = dOut[idx4(n,h_out,w_out,c_out,H-K+1,W-K+1,C_out)];\n",
        "                grad += val_in*val_dout;\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    dW[((c_in*K+kh)*K+kw)*C_out + c_out] += grad;\n",
        "}\n",
        "\n",
        "// MaxPool Backward Kernel\n",
        "__global__ void maxPoolBackwardKernel(const float* __restrict__ dOut,\n",
        "                                      float* __restrict__ dIn,\n",
        "                                      const int* __restrict__ max_idx,\n",
        "                                      int N, int H_in, int W_in, int C,\n",
        "                                      int stride) {\n",
        "    int n = blockIdx.x;\n",
        "    int oh = threadIdx.y;\n",
        "    int ow = threadIdx.x;\n",
        "    for (int c=0;c<C;c++){\n",
        "        int out_idx = idx4(n,oh,ow,c,H_in/stride,W_in/stride,C);\n",
        "        float grad_val = dOut[out_idx];\n",
        "        int max_pos = max_idx[out_idx];\n",
        "        // Only the max position gets the gradient\n",
        "        atomicAdd(&dIn[max_pos], grad_val);\n",
        "    }\n",
        "}\n",
        "\n",
        "// FC Backward Kernels\n",
        "__global__ void fcBackwardKernel(const float* __restrict__ input,\n",
        "                                 const float* __restrict__ dOut,\n",
        "                                 float* __restrict__ dIn,\n",
        "                                 float* __restrict__ dW,\n",
        "                                 float* __restrict__ dB,\n",
        "                                 int N, int D_in, int D_out) {\n",
        "    int n = blockIdx.x;\n",
        "    // Compute gradients w.r.t input\n",
        "    for (int d=0;d<D_in;d++){\n",
        "        float grad_val=0.0f;\n",
        "        for (int d_o=0;d_o<D_out;d_o++){\n",
        "            float dw = dW[d*D_out + d_o]; // w used for grad w.r.t in?\n",
        "            // Actually we should use original weights (not gradient), so we might need original w.\n",
        "            // Let's assume we have original weights in global memory accessible.\n",
        "            // In this kernel we just accumulate dW and dB.\n",
        "        }\n",
        "    }\n",
        "    // Actually, better approach: separate kernels for clarity.\n",
        "\n",
        "    // dB gradient\n",
        "    for (int d_o=0; d_o<D_out; d_o++){\n",
        "        atomicAdd(&dB[d_o], dOut[n*D_out + d_o]);\n",
        "    }\n",
        "\n",
        "    // dW gradient\n",
        "    for (int d_o=0; d_o<D_out; d_o++){\n",
        "        float grad_val = dOut[n*D_out + d_o];\n",
        "        for (int d_i=0; d_i<D_in; d_i++){\n",
        "            atomicAdd(&dW[d_i*D_out + d_o], input[n*D_in + d_i]*grad_val);\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "// FC dIn kernel\n",
        "__global__ void fcBackwardInputKernel(const float* __restrict__ dOut,\n",
        "                                      const float* __restrict__ w,\n",
        "                                      float* __restrict__ dIn,\n",
        "                                      int N, int D_in, int D_out) {\n",
        "    int n = blockIdx.x;\n",
        "    for (int d_i=0; d_i<D_in; d_i++){\n",
        "        float grad_val=0.0f;\n",
        "        for (int d_o=0; d_o<D_out; d_o++){\n",
        "            grad_val += dOut[n*D_out + d_o]*w[d_i*D_out + d_o];\n",
        "        }\n",
        "        dIn[n*D_in + d_i] = grad_val;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Flatten backward kernel (just copy)\n",
        "__global__ void flattenBackwardKernel(const float* dOut, float* dIn, int N, int H, int W, int C) {\n",
        "    int n = blockIdx.x;\n",
        "    int size = H*W*C;\n",
        "    for (int i=0;i<size;i++){\n",
        "        dIn[n*size + i] = dOut[n*size + i];\n",
        "    }\n",
        "}\n",
        "\n",
        "// Softmax backward is usually combined with cross-entropy loss.\n",
        "// For demonstration, we assume dOut is provided from outside.\n",
        "\n",
        "// ---------------------------------------------\n",
        "// Base Layer Class\n",
        "// ---------------------------------------------\n",
        "class Layer {\n",
        "public:\n",
        "    virtual ~Layer() {}\n",
        "    bool isConvOrPool = false;\n",
        "\n",
        "    // Store forward input/output for backward\n",
        "    float *input_cache = nullptr;\n",
        "    float *output_cache = nullptr;\n",
        "\n",
        "    // Output shape after forward\n",
        "    int outN, outH, outW, outC, outD;\n",
        "\n",
        "    virtual float* forward(float* input, int N, int H, int W, int C) {\n",
        "        std::cerr << \"Forward (N,H,W,C) not implemented.\\n\";\n",
        "        return nullptr;\n",
        "    }\n",
        "    virtual float* forward(float* input, int N, int D) {\n",
        "        std::cerr << \"Forward (N,D) not implemented.\\n\";\n",
        "        return nullptr;\n",
        "    }\n",
        "\n",
        "    // backward takes dOut and returns dIn\n",
        "    // For conv/pool: dOut is (N,outH,outW,outC), returns dIn (N,H,W,C)\n",
        "    // For FC: dOut is (N,D_out), returns dIn (N,D_in)\n",
        "    // For flatten: dOut is (N,D), returns dIn (N,H,W,C)\n",
        "    virtual float* backward(float* dOut) {\n",
        "        std::cerr << \"Backward not implemented.\\n\";\n",
        "        return nullptr;\n",
        "    }\n",
        "\n",
        "    // For layers with parameters, store gradients here and implement parameter update later.\n",
        "    virtual void zeroGrad() {}\n",
        "    virtual void updateParams(float lr) {}\n",
        "};\n",
        "\n",
        "// ---------------------------------------------\n",
        "// Conv2D Layer\n",
        "// ---------------------------------------------\n",
        "class Conv2D : public Layer {\n",
        "public:\n",
        "    int window_size, channels, neurons;\n",
        "    float *d_kernel = nullptr;\n",
        "\n",
        "    // For backprop\n",
        "    float *d_kernel_grad = nullptr;\n",
        "    int inH, inW, inC, inN;\n",
        "\n",
        "    Conv2D(int window_size_, int channels_, int neurons_):\n",
        "        window_size(window_size_), channels(channels_), neurons(neurons_) {\n",
        "        int k_size = channels*window_size*window_size*neurons;\n",
        "        float *h_kernel = (float*)malloc(k_size*sizeof(float));\n",
        "        for (int i = 0; i < k_size; i++)\n",
        "            h_kernel[i] = (float)rand()/RAND_MAX;\n",
        "        CUDA_CALL(cudaMalloc(&d_kernel, k_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemcpy(d_kernel, h_kernel, k_size*sizeof(float), cudaMemcpyHostToDevice));\n",
        "        free(h_kernel);\n",
        "\n",
        "        CUDA_CALL(cudaMalloc(&d_kernel_grad, k_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(d_kernel_grad, 0, k_size*sizeof(float)));\n",
        "\n",
        "        isConvOrPool = true;\n",
        "    }\n",
        "\n",
        "    ~Conv2D() {\n",
        "        if (d_kernel) CUDA_CALL(cudaFree(d_kernel));\n",
        "        if (d_kernel_grad) CUDA_CALL(cudaFree(d_kernel_grad));\n",
        "        // if (input_cache) CUDA_CALL(cudaFree(input_cache));\n",
        "        if (output_cache) CUDA_CALL(cudaFree(output_cache));\n",
        "    }\n",
        "\n",
        "    float* forward(float* input, int N, int H, int W, int C) override {\n",
        "        inN=N; inH=H; inW=W; inC=C;\n",
        "        int outH = H - window_size + 1;\n",
        "        int outW = W - window_size + 1;\n",
        "        int outC = neurons;\n",
        "\n",
        "        // Store input for backward\n",
        "        input_cache = input; // we assume input is from previous layer (already on GPU)\n",
        "        float *d_output;\n",
        "        CUDA_CALL(cudaMalloc(&d_output, N*outH*outW*outC*sizeof(float)));\n",
        "\n",
        "        dim3 blockDim(outW, outH);\n",
        "        dim3 gridDim(N);\n",
        "        convForwardKernel<<<gridDim, blockDim>>>(input, d_kernel, d_output, N, H, W, C, window_size, neurons);\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "        output_cache = d_output;\n",
        "        this->outN = N; this->outH = outH; this->outW = outW; this->outC = outC;\n",
        "        return d_output;\n",
        "    }\n",
        "\n",
        "    float* backward(float* dOut) override {\n",
        "        // dOut: N,outH,outW,outC\n",
        "        // Compute dIn and dW\n",
        "        float *dIn;\n",
        "        CUDA_CALL(cudaMalloc(&dIn, inN*inH*inW*inC*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(dIn,0,inN*inH*inW*inC*sizeof(float)));\n",
        "\n",
        "        // zeroGrad for kernel\n",
        "        CUDA_CALL(cudaMemset(d_kernel_grad, 0, channels*window_size*window_size*neurons*sizeof(float)));\n",
        "\n",
        "        // Compute dIn & dW\n",
        "        {\n",
        "            dim3 grid(inN);\n",
        "            convBackwardKernel<<<grid,1>>>(input_cache, dOut, dIn, d_kernel, inN,inH,inW,inC,window_size,neurons);\n",
        "        }\n",
        "\n",
        "        {\n",
        "            dim3 gridW(neurons);\n",
        "            dim3 blockW(channels, window_size, window_size);\n",
        "            convBackwardWeightKernel<<<gridW, blockW>>>(input_cache, dOut, d_kernel_grad, inN, inH, inW, inC, window_size, neurons);\n",
        "        }\n",
        "\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "        return dIn;\n",
        "    }\n",
        "\n",
        "    void zeroGrad() override {\n",
        "        CUDA_CALL(cudaMemset(d_kernel_grad,0,channels*window_size*window_size*neurons*sizeof(float)));\n",
        "    }\n",
        "\n",
        "    void updateParams(float lr) override {\n",
        "        // W = W - lr*dW\n",
        "        int size = channels*window_size*window_size*neurons;\n",
        "        thrust::device_ptr<float> w_ptr(d_kernel);\n",
        "        thrust::device_ptr<float> dw_ptr(d_kernel_grad);\n",
        "        for (int i=0;i<size;i++){\n",
        "            w_ptr[i] -= lr*dw_ptr[i];\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "// ---------------------------------------------\n",
        "// MaxPool Layer\n",
        "// ---------------------------------------------\n",
        "class MaxPool : public Layer {\n",
        "public:\n",
        "    int stride;\n",
        "    int inH,inW,inC,inN;\n",
        "    int *d_max_idx=nullptr;\n",
        "\n",
        "    MaxPool(int stride_): stride(stride_) {\n",
        "        isConvOrPool = true;\n",
        "    }\n",
        "\n",
        "    ~MaxPool() {\n",
        "        if (d_max_idx) CUDA_CALL(cudaFree(d_max_idx));\n",
        "        // if (input_cache && input_cache!=output_cache) CUDA_CALL(cudaFree(input_cache));\n",
        "        if (output_cache) CUDA_CALL(cudaFree(output_cache));\n",
        "    }\n",
        "\n",
        "    float* forward(float* input, int N, int H, int W, int C) override {\n",
        "        inN=N; inH=H; inW=W; inC=C;\n",
        "        int outH = H/stride;\n",
        "        int outW = W/stride;\n",
        "        int outC = C;\n",
        "        float *d_output;\n",
        "        CUDA_CALL(cudaMalloc(&d_output, N*outH*outW*C*sizeof(float)));\n",
        "        CUDA_CALL(cudaMalloc(&d_max_idx, N*outH*outW*C*sizeof(int)));\n",
        "\n",
        "        dim3 blockDim(outW, outH);\n",
        "        dim3 gridDim(N);\n",
        "        maxPoolForwardKernel<<<gridDim, blockDim>>>(input, d_output, d_max_idx, N, H, W, C, stride);\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "        input_cache = input;\n",
        "        output_cache = d_output;\n",
        "        this->outN=N; this->outH=outH; this->outW=outW; this->outC=outC;\n",
        "        return d_output;\n",
        "    }\n",
        "\n",
        "    float* backward(float* dOut) override {\n",
        "        // dOut: N,outH,outW,outC\n",
        "        // We know exactly where each output came from.\n",
        "        float *dIn;\n",
        "        CUDA_CALL(cudaMalloc(&dIn, inN*inH*inW*inC*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(dIn, 0, inN*inH*inW*inC*sizeof(float)));\n",
        "\n",
        "        dim3 blockDim(outW, outH);\n",
        "        dim3 gridDim(inN);\n",
        "        maxPoolBackwardKernel<<<gridDim, blockDim>>>(dOut, dIn, d_max_idx, inN, inH, inW, inC, stride);\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "        return dIn;\n",
        "    }\n",
        "};\n",
        "\n",
        "// ---------------------------------------------\n",
        "// Flatten Layer\n",
        "// ---------------------------------------------\n",
        "class Flatten : public Layer {\n",
        "public:\n",
        "    int inN,inH,inW,inC;\n",
        "    Flatten() {\n",
        "        isConvOrPool = false;\n",
        "    }\n",
        "\n",
        "    float* forward(float* input, int N, int H, int W, int C) override {\n",
        "        inN=N;inH=H;inW=W;inC=C;\n",
        "        int D = H*W*C;\n",
        "        float *d_output;\n",
        "        CUDA_CALL(cudaMalloc(&d_output, N*D*sizeof(float)));\n",
        "        // Flatten kernel\n",
        "        for (int i=0;i<N;i++){\n",
        "            // we can just do a cudaMemcpy for simplicity, since memory is contiguous\n",
        "            // input and output have same indexing pattern for flatten.\n",
        "            // Actually indexing matches (N,H,W,C) vs (N,D) but memory layout is contiguous anyway.\n",
        "            CUDA_CALL(cudaMemcpy(d_output + i*D, input + i*D, D*sizeof(float), cudaMemcpyDeviceToDevice));\n",
        "        }\n",
        "\n",
        "        input_cache = input;\n",
        "        output_cache = d_output;\n",
        "        this->outN = N; this->outD = D; this->outH=0; this->outW=0; this->outC=0;\n",
        "        return d_output;\n",
        "    }\n",
        "\n",
        "    float* backward(float* dOut) override {\n",
        "        // dOut: (N,D)\n",
        "        // dIn: (N,H,W,C)\n",
        "        int D = inH*inW*inC;\n",
        "        float *dIn;\n",
        "        CUDA_CALL(cudaMalloc(&dIn, inN*D*sizeof(float)));\n",
        "        // Just copy back\n",
        "        for (int i=0;i<inN;i++){\n",
        "            CUDA_CALL(cudaMemcpy(dIn + i*D, dOut + i*D, D*sizeof(float), cudaMemcpyDeviceToDevice));\n",
        "        }\n",
        "        return dIn;\n",
        "    }\n",
        "};\n",
        "\n",
        "\n",
        "// ---------------------------------------------\n",
        "// FC Layer\n",
        "// ---------------------------------------------\n",
        "class FC : public Layer {\n",
        "public:\n",
        "    int input_size, output_size;\n",
        "    float *d_w=nullptr, *d_b=nullptr;\n",
        "\n",
        "    // For backward\n",
        "    float *d_w_grad=nullptr, *d_b_grad=nullptr;\n",
        "    int inN,inD;\n",
        "\n",
        "    float *weight_copy = nullptr; // store weights for backward computations\n",
        "\n",
        "    FC(int in_size, int out_size): input_size(in_size), output_size(out_size) {\n",
        "        float *h_w=(float*)malloc(in_size*out_size*sizeof(float));\n",
        "        float *h_b=(float*)malloc(out_size*sizeof(float));\n",
        "        for(int i=0;i<in_size*out_size;i++) h_w[i]=(float)rand()/RAND_MAX*0.01f;\n",
        "        for(int i=0;i<out_size;i++) h_b[i]=(float)rand()/RAND_MAX*0.01f;\n",
        "        CUDA_CALL(cudaMalloc(&d_w,in_size*out_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMalloc(&d_b,out_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemcpy(d_w,h_w,in_size*out_size*sizeof(float),cudaMemcpyHostToDevice));\n",
        "        CUDA_CALL(cudaMemcpy(d_b,h_b,out_size*sizeof(float),cudaMemcpyHostToDevice));\n",
        "        free(h_w);free(h_b);\n",
        "\n",
        "        CUDA_CALL(cudaMalloc(&d_w_grad,in_size*out_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMalloc(&d_b_grad,out_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(d_w_grad,0,in_size*out_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(d_b_grad,0,out_size*sizeof(float)));\n",
        "\n",
        "        isConvOrPool = false;\n",
        "    }\n",
        "    ~FC(){\n",
        "        CUDA_CALL(cudaFree(d_w));\n",
        "        CUDA_CALL(cudaFree(d_b));\n",
        "        CUDA_CALL(cudaFree(d_w_grad));\n",
        "        CUDA_CALL(cudaFree(d_b_grad));\n",
        "        // if (input_cache) CUDA_CALL(cudaFree(input_cache));\n",
        "        // if (output_cache) CUDA_CALL(cudaFree(output_cache));\n",
        "    }\n",
        "\n",
        "    float* forward(float* input, int N, int D) override {\n",
        "        inN=N;inD=D;\n",
        "        if (D!=input_size) {std::cerr<<\"FC forward dimension mismatch!\\n\";}\n",
        "\n",
        "        float* d_output;\n",
        "        CUDA_CALL(cudaMalloc(&d_output, N*output_size*sizeof(float)));\n",
        "        dim3 gridDim(N);\n",
        "        fcForwardKernel<<<gridDim,1>>>(input,d_w,d_b,d_output,N,input_size,output_size);\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "        input_cache = input;\n",
        "        output_cache = d_output;\n",
        "        this->outN = N; this->outD = output_size;\n",
        "        return d_output;\n",
        "    }\n",
        "\n",
        "    float* backward(float* dOut) override {\n",
        "        // dOut: (N, output_size)\n",
        "        // We compute dIn: (N, input_size)\n",
        "        float *dIn;\n",
        "        CUDA_CALL(cudaMalloc(&dIn, inN*inD*sizeof(float)));\n",
        "\n",
        "        // zero out gradients\n",
        "        CUDA_CALL(cudaMemset(d_w_grad,0,input_size*output_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(d_b_grad,0,output_size*sizeof(float)));\n",
        "\n",
        "        // Compute gradients w.r.t. W and B\n",
        "        {\n",
        "            dim3 gridDim(inN);\n",
        "            fcBackwardKernel<<<gridDim,1>>>(input_cache, dOut, dIn, d_w_grad, d_b_grad, inN, input_size, output_size);\n",
        "        }\n",
        "\n",
        "        // Compute gradients w.r.t input\n",
        "        // Need weights for this\n",
        "        {\n",
        "            dim3 gridDim(inN);\n",
        "            fcBackwardInputKernel<<<gridDim,1>>>(dOut, d_w, dIn, inN, input_size, output_size);\n",
        "        }\n",
        "\n",
        "        CUDA_CALL(cudaDeviceSynchronize());\n",
        "        return dIn;\n",
        "    }\n",
        "\n",
        "    void zeroGrad() override {\n",
        "        CUDA_CALL(cudaMemset(d_w_grad,0,input_size*output_size*sizeof(float)));\n",
        "        CUDA_CALL(cudaMemset(d_b_grad,0,output_size*sizeof(float)));\n",
        "    }\n",
        "\n",
        "    void updateParams(float lr) override {\n",
        "        int w_size = input_size*output_size;\n",
        "        thrust::device_ptr<float> w_ptr(d_w);\n",
        "        thrust::device_ptr<float> dw_ptr(d_w_grad);\n",
        "        for (int i=0;i<w_size;i++){\n",
        "            w_ptr[i] -= lr*dw_ptr[i];\n",
        "        }\n",
        "\n",
        "        thrust::device_ptr<float> b_ptr(d_b);\n",
        "        thrust::device_ptr<float> db_ptr(d_b_grad);\n",
        "        for (int i=0;i<output_size;i++){\n",
        "            b_ptr[i] -= lr*db_ptr[i];\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "\n",
        "float computeAccuracy(float* d_predictions, float* d_labels, int N, int D) {\n",
        "    // predictions are (N,D) probabilities after softmax\n",
        "    // labels are one-hot (N,D)\n",
        "    // We find argmax of predictions and compare with argmax of labels\n",
        "    float *h_predictions=(float*)malloc(N*D*sizeof(float));\n",
        "    float *h_labels=(float*)malloc(N*D*sizeof(float));\n",
        "\n",
        "    CUDA_CALL(cudaMemcpy(h_predictions,d_predictions,N*D*sizeof(float),cudaMemcpyDeviceToHost));\n",
        "    CUDA_CALL(cudaMemcpy(h_labels,d_labels,N*D*sizeof(float),cudaMemcpyDeviceToHost));\n",
        "\n",
        "    int correct=0;\n",
        "    for (int n=0;n<N;n++){\n",
        "        int pred_class=0;\n",
        "        float pred_val=-1.0f;\n",
        "        int true_class=0;\n",
        "        for (int d=0; d<D; d++){\n",
        "            float p=h_predictions[n*D + d];\n",
        "            if (p>pred_val){\n",
        "                pred_val=p;\n",
        "                pred_class=d;\n",
        "            }\n",
        "            if (h_labels[n*D + d]==1.0f){\n",
        "                true_class=d;\n",
        "            }\n",
        "        }\n",
        "        if (pred_class==true_class) correct++;\n",
        "    }\n",
        "\n",
        "    free(h_predictions);\n",
        "    free(h_labels);\n",
        "    return (float)correct/N;\n",
        "}\n",
        "\n",
        "// Softmax (in-place)\n",
        "void softmax(float* d_data, int N, int D) {\n",
        "    softmaxKernel<<<N,1>>>(d_data,N,D);\n",
        "    CUDA_CALL(cudaDeviceSynchronize());\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// -------------------------------------------------------------------\n",
        "// Kernel to compute Cross Entropy Loss and its gradient w.r.t predictions\n",
        "// predictions: (N,D) after softmax\n",
        "// labels: (N,D) one-hot\n",
        "// dLoss/dPred: (N,D)\n",
        "// loss out: scalar (we can store partial sums and reduce)\n",
        "__global__ void crossEntropyKernel(const float* predictions, const float* labels,\n",
        "                                   float* dLoss_dPred, float* loss_buffer,\n",
        "                                   int N, int D) {\n",
        "    int n = blockIdx.x;\n",
        "    float loss_val = 0.0f;\n",
        "    for (int d=0; d<D; d++){\n",
        "        float y = labels[n*D + d];\n",
        "        float p = predictions[n*D + d];\n",
        "        // Avoid log(0) by adding small epsilon if needed\n",
        "        if(y > 0.0f) {\n",
        "            loss_val -= logf(p+1e-9f);\n",
        "        }\n",
        "        // Gradient w.r.t prediction (P - Y)\n",
        "        dLoss_dPred[n*D + d] = p - y;\n",
        "    }\n",
        "    loss_buffer[n] = loss_val;\n",
        "}\n",
        "\n",
        "__global__ void crossEntropyOnlyKernel(const float* pred, const float* lab, float* loss_buf, int N, int D) {\n",
        "        int n = blockIdx.x;\n",
        "        float loss_val=0.0f;\n",
        "        for (int d=0; d<D; d++){\n",
        "            float y = lab[n*D + d];\n",
        "            float p = pred[n*D + d];\n",
        "            if(y>0.0f) loss_val -= logf(p+1e-9f);\n",
        "        }\n",
        "        loss_buf[n] = loss_val;\n",
        "    };\n",
        "\n",
        "\n",
        "// Function to compute cross-entropy loss and gradient\n",
        "float crossEntropyLossAndGradient(float* d_predictions, float* d_labels,\n",
        "                                  float* d_dLoss_dPred, int N, int D) {\n",
        "    // Allocate buffer for partial losses\n",
        "    float *d_loss_buffer;\n",
        "    CUDA_CALL(cudaMalloc(&d_loss_buffer, N*sizeof(float)));\n",
        "\n",
        "    // Launch kernel\n",
        "    crossEntropyKernel<<<N,1>>>(d_predictions, d_labels, d_dLoss_dPred, d_loss_buffer, N, D);\n",
        "    CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "    // Copy loss buffer to host and sum up\n",
        "    float *h_loss_buffer = (float*)malloc(N*sizeof(float));\n",
        "    CUDA_CALL(cudaMemcpy(h_loss_buffer, d_loss_buffer, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    float loss=0.0f;\n",
        "    for (int i=0;i<N;i++){\n",
        "        loss += h_loss_buffer[i];\n",
        "    }\n",
        "    loss /= N; // average over batch\n",
        "\n",
        "    free(h_loss_buffer);\n",
        "    CUDA_CALL(cudaFree(d_loss_buffer));\n",
        "\n",
        "    return loss;\n",
        "}\n",
        "\n",
        "// A helper to compute just the cross entropy loss without gradient:\n",
        "float crossEntropyLossOnly(float* d_predictions, float* d_labels, int N, int D) {\n",
        "    // Similar to above but no gradient needed:\n",
        "    float *d_loss_buffer;\n",
        "    CUDA_CALL(cudaMalloc(&d_loss_buffer, N*sizeof(float)));\n",
        "\n",
        "    // Use a modified kernel that doesn't compute gradients:\n",
        "    // For simplicity, we can just reuse the existing kernel by passing in NULL for dLoss_dPred\n",
        "    // but we must ensure that kernel checks for NULL. Let's just reimplement a simple kernel here.\n",
        "\n",
        "    crossEntropyOnlyKernel<<<N,1>>>(d_predictions, d_labels, d_loss_buffer, N, D);\n",
        "    CUDA_CALL(cudaDeviceSynchronize());\n",
        "\n",
        "    float *h_loss_buffer = (float*)malloc(N*sizeof(float));\n",
        "    CUDA_CALL(cudaMemcpy(h_loss_buffer, d_loss_buffer, N*sizeof(float), cudaMemcpyDeviceToHost));\n",
        "    float loss=0.0f;\n",
        "    for (int i=0;i<N;i++){\n",
        "        loss+=h_loss_buffer[i];\n",
        "    }\n",
        "    loss/=N;\n",
        "\n",
        "    free(h_loss_buffer);\n",
        "    CUDA_CALL(cudaFree(d_loss_buffer));\n",
        "    return loss;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "// ---------------------------------------------\n",
        "// Model Class\n",
        "// ---------------------------------------------\n",
        "class Model {\n",
        "public:\n",
        "    std::vector<Layer*> layers;\n",
        "\n",
        "    void addLayer(Layer* layer) {\n",
        "        layers.push_back(layer);\n",
        "    }\n",
        "\n",
        "    float* forward(float* input, int N, int H, int W, int C) {\n",
        "        int curN=N, curH=H, curW=W, curC=C, curD=0;\n",
        "        float* current_data = input;\n",
        "        for (auto l : layers) {\n",
        "            if (l->isConvOrPool) {\n",
        "                current_data = l->forward(current_data, curN, curH, curW, curC);\n",
        "                curN = l->outN; curH = l->outH; curW = l->outW; curC = l->outC;\n",
        "                curD = 0;\n",
        "            } else {\n",
        "                if (dynamic_cast<Flatten*>(l)) {\n",
        "                    current_data = l->forward(current_data, curN, curH, curW, curC);\n",
        "                    curN = l->outN; curD = l->outD;\n",
        "                    curH=0; curW=0; curC=0;\n",
        "                } else {\n",
        "                    current_data = l->forward(current_data, curN, curD);\n",
        "                    curN = l->outN; curD = l->outD;\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        return current_data;\n",
        "    }\n",
        "\n",
        "    float* backward(float* dLoss_dOut) {\n",
        "        // dLoss_dOut is gradient of loss w.r.t final output of model\n",
        "        // We propagate backwards through layers\n",
        "        float* current_grad = dLoss_dOut;\n",
        "        for (int i=(int)layers.size()-1; i>=0; i--) {\n",
        "            current_grad = layers[i]->backward(current_grad);\n",
        "        }\n",
        "        return current_grad; // this is dLoss/dInput of the entire model\n",
        "    }\n",
        "\n",
        "    void zeroGrad() {\n",
        "        for (auto l: layers) {\n",
        "            l->zeroGrad();\n",
        "        }\n",
        "    }\n",
        "\n",
        "    void updateParams(float lr) {\n",
        "        for (auto l: layers) {\n",
        "            l->updateParams(lr);\n",
        "        }\n",
        "    }\n",
        "};\n",
        "\n",
        "int main() {\n",
        "    int num_classes = 10;\n",
        "    int train_size = 10000;   // total training samples\n",
        "    int test_size = 1000;     // total test samples\n",
        "    int N=5000;\n",
        "    int epochs = 10;\n",
        "    float learning_rate = 0.00001f;\n",
        "    int H=28, W=28, C=1;\n",
        "\n",
        "    std::cout << \"Beginning Program!!!!!!\" << std::endl;\n",
        "\n",
        "    int img_rows, img_cols;\n",
        "    float* h_train_images = (float*)malloc(train_size * H * W * C * sizeof(float));\n",
        "    readMNISTImages(\"mnist-train-images\", h_train_images, train_size, img_rows, img_cols);\n",
        "    std::cout << \"Read training images file in.\" << std::endl;\n",
        "\n",
        "    float* h_train_labels = (float*)malloc(train_size*num_classes*sizeof(float));\n",
        "    readMNISTLabels(\"mnist-train-labels\", h_train_labels, train_size, num_classes);\n",
        "    std::cout << \"Read training labels file in.\" << std::endl;\n",
        "\n",
        "\n",
        "    float* h_test_images = (float*)malloc(test_size * H * W * C * sizeof(float));\n",
        "    readMNISTImages(\"mnist-test-images\", h_test_images, test_size, img_rows, img_cols);\n",
        "    std::cout << \"Read testing images file in.\" << std::endl;\n",
        "\n",
        "    float* h_test_labels = (float*)malloc(test_size*num_classes*sizeof(float));\n",
        "    readMNISTLabels(\"mnist-test-labels\", h_test_labels, test_size, num_classes);\n",
        "    std::cout << \"Read testing labels file in.\" << std::endl;\n",
        "\n",
        "\n",
        "    // Copy entire dataset to GPU (in practice you might do this batch-by-batch)\n",
        "    float *d_train_input;\n",
        "    float *d_train_labels;\n",
        "    cudaMalloc(&d_train_input, train_size*H*W*C*sizeof(float));\n",
        "    cudaMalloc(&d_train_labels, train_size*num_classes*sizeof(float));\n",
        "    cudaMemcpy(d_train_input,h_train_images,train_size*H*W*C*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_train_labels,h_train_labels,train_size*num_classes*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "    float *d_test_input,*d_test_labels;\n",
        "    cudaMalloc(&d_test_input,test_size*H*W*C*sizeof(float));\n",
        "    cudaMalloc(&d_test_labels,test_size*num_classes*sizeof(float));\n",
        "    cudaMemcpy(d_test_input,h_test_images,test_size*H*W*C*sizeof(float),cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_test_labels,h_test_labels,test_size*num_classes*sizeof(float),cudaMemcpyHostToDevice);\n",
        "\n",
        "\n",
        "    // Build model\n",
        "    Model model;\n",
        "    model.addLayer(new Conv2D(3,1,30));    // (N,28,28,1) -> (N,26,26,30)\n",
        "    model.addLayer(new MaxPool(2));        // (N,26,26,30) -> (N,13,13,30)\n",
        "    model.addLayer(new Flatten());         // (N,13,13,30) -> (N,5070)\n",
        "    model.addLayer(new FC(13*13*30,10));  // (N,6750) -> (N,10)\n",
        "\n",
        "    std::cout << \"Created model. \" << std::endl;\n",
        "\n",
        "    int batch_size = N; // from above N=2\n",
        "    int steps_per_epoch = train_size / batch_size; // integer division\n",
        "\n",
        "    std::cout << \"===== Beginning Training w/ training_set_size: \" << train_size <<\n",
        "      \"  batch_size: \" << batch_size << \"  epochs: \" << epochs <<\n",
        "      \"  steps/epoch: \" << steps_per_epoch << \"  learning_rate: \" << learning_rate << \" =====\" << std::endl;\n",
        "    for (int epoch=0; epoch<epochs; epoch++){\n",
        "        std::cout << \"Starting Epoch \" << (epoch + 1) << std::endl;\n",
        "\n",
        "        float epoch_loss=0.0f;\n",
        "        std::cout << \"\\t\";\n",
        "\n",
        "        // Training loop over batches\n",
        "        for (int step=0; step<steps_per_epoch; step++){\n",
        "            int start_idx = step*batch_size;\n",
        "            // Pointers to this batch\n",
        "            float *d_batch_input = d_train_input + start_idx*(H*W*C);\n",
        "            float *d_batch_labels = d_train_labels + start_idx*(num_classes);\n",
        "\n",
        "            // Forward pass\n",
        "            float *d_out = model.forward(d_batch_input, batch_size, H, W, C);\n",
        "            softmax(d_out,batch_size,num_classes);\n",
        "\n",
        "            // Compute loss and gradient for this batch\n",
        "            float *d_dLoss_dOut;\n",
        "            cudaMalloc(&d_dLoss_dOut,batch_size*num_classes*sizeof(float));\n",
        "            float batch_loss = crossEntropyLossAndGradient(d_out, d_batch_labels, d_dLoss_dOut, batch_size, num_classes);\n",
        "            epoch_loss += batch_loss;\n",
        "\n",
        "            // Backprop\n",
        "            model.zeroGrad();\n",
        "            float *d_dLoss_dIn = model.backward(d_dLoss_dOut);\n",
        "\n",
        "            // Update parameters\n",
        "            model.updateParams(learning_rate);\n",
        "\n",
        "            // Cleanup this batch\n",
        "            cudaFree(d_out);\n",
        "            cudaFree(d_dLoss_dOut);\n",
        "            cudaFree(d_dLoss_dIn);\n",
        "\n",
        "            std::cout << \"*\";\n",
        "        }\n",
        "\n",
        "        std::cout << std::endl;\n",
        "\n",
        "        // Average loss over the epoch\n",
        "        epoch_loss /= steps_per_epoch;\n",
        "\n",
        "        // Evaluate on test set\n",
        "        float *d_test_out = model.forward(d_test_input,test_size,H,W,C);\n",
        "        softmax(d_test_out,test_size,num_classes);\n",
        "        float test_loss = crossEntropyLossOnly(d_test_out,d_test_labels,test_size,num_classes);\n",
        "        float test_acc = computeAccuracy(d_test_out,d_test_labels,test_size,num_classes);\n",
        "\n",
        "        std::cout << \"\\tEpoch \"<<(epoch+1)<<\" Train Loss: \"<<epoch_loss<<\" | Test Loss: \"<<test_loss<<\" | Test Acc: \"<<test_acc<<\"\\n\";\n",
        "\n",
        "        cudaFree(d_test_out);\n",
        "    }\n",
        "\n",
        "    // Cleanup\n",
        "    free(h_train_images); free(h_train_labels);\n",
        "    free(h_test_images); free(h_test_labels);\n",
        "    cudaFree(d_train_input);\n",
        "    cudaFree(d_train_labels);\n",
        "    cudaFree(d_test_input);\n",
        "    cudaFree(d_test_labels);\n",
        "\n",
        "    for (auto l : model.layers) delete l;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFdOLJaCDymM",
        "outputId": "57c1eef0-3611-4bc9-c13d-2a022fda7026"
      },
      "id": "iFdOLJaCDymM",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Beginning Program!!!!!!\n",
            "Read training images file in.\n",
            "Read training labels file in.\n",
            "Read testing images file in.\n",
            "Read testing labels file in.\n",
            "Created model. \n",
            "===== Beginning Training w/ training_set_size: 10000  batch_size: 5000  epochs: 10  steps/epoch: 2  learning_rate: 1e-05 =====\n",
            "Starting Epoch 1\n",
            "\t**\n",
            "\tEpoch 1 Train Loss: 6.07335 | Test Loss: 9.75133 | Test Acc: 0.334\n",
            "Starting Epoch 2\n",
            "\t**\n",
            "\tEpoch 2 Train Loss: 9.11766 | Test Loss: 11.2496 | Test Acc: 0.3\n",
            "Starting Epoch 3\n",
            "\t**\n",
            "\tEpoch 3 Train Loss: 11.2114 | Test Loss: 14.1091 | Test Acc: 0.283\n",
            "Starting Epoch 4\n",
            "\t**\n",
            "\tEpoch 4 Train Loss: 12.9466 | Test Loss: 13.2288 | Test Acc: 0.32\n",
            "Starting Epoch 5\n",
            "\t**\n",
            "\tEpoch 5 Train Loss: 12.2174 | Test Loss: 11.2092 | Test Acc: 0.339\n",
            "Starting Epoch 6\n",
            "\t**\n",
            "\tEpoch 6 Train Loss: 8.65808 | Test Loss: 5.33045 | Test Acc: 0.607\n",
            "Starting Epoch 7\n",
            "\t**\n",
            "\tEpoch 7 Train Loss: 3.51438 | Test Loss: 2.05589 | Test Acc: 0.757\n",
            "Starting Epoch 8\n",
            "\t**\n",
            "\tEpoch 8 Train Loss: 1.68532 | Test Loss: 1.89768 | Test Acc: 0.762\n",
            "Starting Epoch 9\n",
            "\t**\n",
            "\tEpoch 9 Train Loss: 1.60687 | Test Loss: 1.98363 | Test Acc: 0.752\n",
            "Starting Epoch 10\n",
            "\t**\n",
            "\tEpoch 10 Train Loss: 1.74559 | Test Loss: 1.65364 | Test Acc: 0.78\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qDqM1pr6T99g"
      },
      "id": "qDqM1pr6T99g",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}